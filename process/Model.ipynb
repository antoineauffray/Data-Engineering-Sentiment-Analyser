{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m spacy download en\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "nlp = spacy.load('en', parse=True, tag=True, entity=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>freq</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>30178</td>\n",
       "      <td>30178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>5002</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>113665</td>\n",
       "      <td>113665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>148845</td>\n",
       "      <td>148845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            freq     All\n",
       "new_sentiment                \n",
       "negative        30178   30178\n",
       "neutral          5002    5002\n",
       "positive       113665  113665\n",
       "All            148845  148845"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('review_sentiment.csv')\n",
    "df.rename(columns = {'Text':'text', 'sentiment':'new_sentiment'}, inplace=True)\n",
    "df = df[['Score','text','new_sentiment']]\n",
    "df.dropna(inplace=True)\n",
    "pd.crosstab(df.new_sentiment, 'freq', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweet(tweet):\n",
    "  text = word_tokenize(tweet)\n",
    "  new_words= [word for word in text if word.isalpha()]\n",
    "  return new_words\n",
    "\n",
    "def lower_ph(tweet):\n",
    "  text = tweet.lower()\n",
    "  return text\n",
    "\n",
    "def remove_stopwords(tweet):\n",
    "  tweet = [word for word in tweet if not word in stopwords.words('english')]\n",
    "  return tweet\n",
    "\n",
    "def lemmatize_text(tweet):\n",
    "    text = nlp(tweet)\n",
    "    text = ''.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 13min 41s, sys: 17min 34s, total: 2h 31min 16s\n",
      "Wall time: 2h 32min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean_data = []\n",
    "\n",
    "for text in df['text']:\n",
    "    low = lower_ph(text)\n",
    "    tok = tokenize_tweet(low)\n",
    "    stop = remove_stopwords(tok)\n",
    "    lemma = lemmatize_text(str(tok))\n",
    "    clean_data.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = clean_data\n",
    "df.to_csv('review_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('review_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_tweet'], df['new_sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['new_sentiment'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train_y_encoded = encoder.fit_transform(y_train)\n",
    "test_y_encoded = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 640 ms, total: 25.6 s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vect = TfidfVectorizer(max_features=400)\n",
    "tfidf_vect.fit(df['clean_tweet'])\n",
    "train_x_tfidf = tfidf_vect.transform(X_train)\n",
    "test_x_tfidf = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score:  76.01531794820114\n",
      "CPU times: user 482 ms, sys: 12.1 ms, total: 494 ms\n",
      "Wall time: 510 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive = naive_bayes.MultinomialNB().fit(train_x_tfidf,y_train)\n",
    "predictions_NB = naive.predict(test_x_tfidf)\n",
    "print(\"Naive Bayes Accuracy Score: \",accuracy_score(predictions_NB, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier Acurracy Score:  73.36826900466929\n",
      "CPU times: user 4min 11s, sys: 37.9 s, total: 4min 49s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=4, weights='distance').fit(train_x_tfidf,y_train)\n",
    "prediction = clf.predict(test_x_tfidf)\n",
    "print(\"KNeighborsClassifier Acurracy Score: \",accuracy_score(y_test, prediction)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = Pipeline([('vect', CountVectorizer()), \n",
    "                         ('tfidf', TfidfTransformer(use_idf=False)), \n",
    "                         ('clf-svm', SGDClassifier(\n",
    "                             loss='modified_huber', \n",
    "                             penalty='l2', \n",
    "                             alpha=0.0001, \n",
    "                             random_state=42, \n",
    "                             max_iter=20))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score:  83.8053008162854\n"
     ]
    }
   ],
   "source": [
    "predictions = svm.predict(X_test)\n",
    "print(\"SVM Accuracy Score: \",accuracy_score(predictions, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "model = 'svm.sav'\n",
    "joblib.dump(svm, model)\n",
    "\n",
    "model = 'svm.joblib'\n",
    "joblib.dump(svm, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
